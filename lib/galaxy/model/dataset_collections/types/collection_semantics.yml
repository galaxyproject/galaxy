- doc: |
    # Collection Semantics

    This document describes the semantics around working with Galaxy dataset collections.
    In particular it describes how they operate within Galaxy tools and workflows.

    :::{admonition} You Probably Don't Need to Read This
    :class: caution

    Any significantly sophisticated workflow language will have ways to collect data
    into arrays or vectors or dictionaries and apply operations across this data (mapping)
    or reduce the dimensionality of this data (reductions). Typically, this explicitly
    annotated with map functions or for loops. Galaxy however is designed to be a point
    and click interface for connecting steps and running tools. It is important that steps
    just connect and just do the most natural thing - and this is what Galaxy does.
    This document just provides a mathematical formalism to that "what should just
    intuitively work" that can be used to document test cases and help with implementation.
    This is reference documentation not user documentation, Galaxy should just work.
    :::

    ## Mapping

    If a tool consumes a simple dataset parameter and produces a simple dataset parameter,
    then any collection type may be "mapped over" the data input to that tool. The result of
    that is the tool being applied to each element of the collection and "implicit collections"
    being created from the outputs that are produced from those operations. Those implicit
    collections have the same element identifiers in the same order as the input collection that is
    mapped over. Each element of the implicit collections correspond to their own job and
    Galaxy very naturally and intuitively parallelizes jobs without extra work from the user
    and without any knowledge of the tool.

- example:
    label: BASIC_MAPPING_PAIRED
    assumptions:
    - datasets: [d_f, d_r]
    - tool:
        in: {i: dataset}
        out: {o: dataset}
    - collections:
        C: [paired, {forward: d_f, reverse: d_r}]
    then: "tool(i=mapOver(C)) ~> {o: collection<paired, {forward=tool(i=d_f)[o], reverse=tool(i=d_r)[o]}> }"
    tests:
        tool_runtime:
            api_test: "test_tool_execute.py::test_map_over_collection"
        wf_editor: "accepts paired data -> data connection"

- example:
    label: BASIC_MAPPING_PAIRED_OR_UNPAIRED_PAIRED
    assumptions:
    - datasets: [d_f, d_r]
    - tool:
        in: {i: dataset}
        out: {o: dataset}
    - collections:
        C: [paired_or_unpaired, {forward: d_f, reverse: d_r}]
    then: "tool(i=mapOver(C)) ~> {o: collection<paired_or_unpaired,{forward=tool(i=d_f)[o], reverse=tool(i=d_r)[o]}>}"
    tests:
        tool_runtime:
            api_test: "test_tool_execute.py::test_map_over_data_with_paired_or_unpaired_unpaired"
        workflow_editor: "accepts paired_or_unpaired data -> data connection"

- example:
    label: BASIC_MAPPING_PAIRED_OR_UNPAIRED_UNPAIRED
    assumptions:
    - datasets: [d_u]
    - tool:
        in: {i: dataset}
        out: {o: dataset}
    - collections:
        C: [paired_or_unpaired, {unpaired: d_u}]
    then: "tool(i=mapOver(C)) ~> {o: collection<paired_or_unpaired,{unpaired=tool(i=d_u)[o]}>}"
    tests:
        tool_runtime:
            api_test: "test_tool_execute.py::test_map_over_data_with_paired_or_unpaired_paired"
        workflow_editor: "accepts paired_or_unpaired data -> data connection"

- example:
    label: BASIC_MAPPING_LIST
    assumptions:
    - datasets: ["d_1,...,d_n"]
    - tool:
        in: {i: dataset}
        out: {o: dataset}
    - collections:
        C: [list, {i1: "d_1", ..., in: "d_n"}]
    then: "tool(i=mapOver(C)) ~> {o: collection<list,{i1=tool(i=d_1)[o],...,in=tool(i=d_n)[o]]}>}"
    tests:
        workflow_editor: "accepts collection data -> data connection"

- doc: |
    The above description of mapping over inputs works naturally and as expected for
    nested collections.

- example:
    label: NESTED_LIST_MAPPING
    assumptions:
    - datasets: ["d_1,...,d_n"]
    - tool:
        in: {i: dataset}
        out: {o: dataset}
    - collections:
        C: ["list:list", {o1: {inner: d_1}, ..., "on": {inner: d_n}}]
    then: "tool(i=mapOver(C)) ~> {o: collection<list:list,{o1={inner=tool(i=d_1)[o]}},...,{on={inner=tool(i=d_n)[o]}}>}"
    tests:
        tool_runtime:
            api_test: "test_tools.py::TestToolsApi::test_map_over_nested_collections"
        workflow_editor: "accepts list:list data -> data connection"

- example:
    label: BASIC_MAPPING_LIST_PAIRED_OR_UNPAIRED
    assumptions:
    - datasets: [d_f, d_r]
    - tool:
        in: {i: dataset}
        out: {o: dataset}
    - collections:
        C: ["list:paired_or_unpaired", {el1: {forward: d_f, reverse: d_r}}]
    then: "tool(i=mapOver(C)) ~> {o: collection<list:paired_or_unpaired,{el1={forward=tool(i=d_f)[o],reverse=tool(i=d_r)[o]}}>}"
    tests:
        tool_runtime:
            api_test: "test_tool_execute.py::test_map_over_data_with_list_paired_or_unpaired"
        workflow_editor: "accepts list:paired_or_unpaired data -> data connection"

- doc: |

    For tools with multiple data inputs, the tool can be executed with individual
    datasets for the non-mapped over input and each tool execution will just be executed
    with that dataset. The dataset not mapped over serves as the input for each execution.

- example:
    label: BASIC_MAPPING_INCLUDING_SINGLE_DATASET
    assumptions:
    - datasets: ["d_1,...,d_n", "d_o"]
    - tool:
        in: {i: dataset, i2: dataset}
        out: {o: dataset}
    - collections:
        C: ["list", {i1: d_1, ..., in: d_n}]
    then: "tool(i=mapOver(C),i2=d_o) ~> {o: collection<list,{i1=tool(i=d_1, i2=d_o)[o],...,in=tool(i=d_n, i2=d_o)[o]}>}"
    tests:
        tool_runtime:
            api_test: "test_tools.py::TestToolsApi::test_map_over_collected_and_individual_datasets"

- doc: |
    If a tool consumes two input datasets and produces one output dataset, you can map two
    collections with identical structure (same element identifiers in the same order) over
    the respective inputs and the result is an implicit collection with the same structure
    as the inputs and where each output in the implicit collection corresponds to the tool
    being executed with the two inputs corresponding to that position in the input
    collections.

    The default behavior here is the collections are linked and the act of mapping over
    inputs to the tool are sort of a flat map or a dot product. No extra dimensionality
    in the resulting collections.

    From a user perspective this means if you start with a collection and apply a bunch
    of map over operations on tools - the results will all continue to match and work together
    very naturally - again without extra work by the user and without extra knowledge
    by the tool author.

- example:
    label: BASIC_MAPPING_TWO_INPUTS_WITH_IDENTICAL_STRUCTURE
    assumptions:
    - datasets: ["d1_1,...,d1_n", "d2_1,...,d2_n"]
    - tool:
        in: {i: dataset, i2: dataset}
        out: {o: dataset}
    - collections:
        C1: ["list", {i1: d1_1, ..., in: d1_n}]
        C2: ["list", {i1: d2_1, ..., in: d2_n}]
    then: "tool(i=mapOver(C1), i2=mapOver(C2)) ~> {o: collection<list,{i1=tool(i=d1_1, i2=d2_1)[o],...,in=tool(i=d1_n, i2=d2_n)[o]]}>}"
    tests:
        tool_runtime:
            api_test: test_tools.py::TestToolsApi::test_map_over_two_collections

- doc: "## Reduction"
- doc: | 
    Not all tool executions result in implicit collections and mapping
    over inputs. Tool inputs of ``type`` ``data_collection`` can consume
    collections directly and do not necessarily result in mapping over.

    Tools that consume collections and output datasets effectively
    reduce the dimension of the Galaxy data structure. When used at runtime
    this is often referred to a "reduction" in the code.

- example:
    label: COLLECTION_INPUT_PAIRED
    assumptions:
    - datasets: ["d_f", "d_r"]
    - tool:
        in: {i: "collection<paired>"}
        out: {o: dataset}
    - collections:
        C: [paired, {forward: d_f, reverse: d_r}]
    then: "tool(i=C) -> {o: dataset}"
    tests:
        tool_runtime: 
            tool: collection_paired_test
        workflow_editor: "accepts paired -> paired connection"

- example:
    label: COLLECTION_INPUT_LIST
    assumptions:
    - datasets: ["d1,...,dn"]
    - tool:
        in: {i: "collection<list>"}
        out: {o: dataset}
    - collections:
        C: [list, {el1: d_1, ..., eln: d_n}]
    then: "tool(i=C) -> {o: dataset}"
    tests:
        workflow_editor: "accepts list -> list connection"

- example:
    label: COLLECTION_INPUT_PAIRED_OR_UNPAIRED
    assumptions:
    - datasets: [d_f, d_r]
    - tool:
        in: {i: "collection<paired_or_unpaired>"}
        out: {o: dataset}
    - collections:
        C: [paired_or_unpaired, {forward: d_f, reverse: d_r}]
    then: "tool(i=C) -> {o: dataset}"
    tests:
        tool_runtime:
            tool: collection_paired_or_unpaired
        workflow_editor: "accepts paired_or_unpaired data -> paired_or_unpaired connection"

- example:
    label: COLLECTION_INPUT_LIST_PAIRED_OR_UNPAIRED
    assumptions:
    - datasets: [d_f, d_r]
    - tool:
        in: {i: "collection<list:paired_or_unpaired>"}
        out: {o: dataset}
    - collections:
        C: ["list:paired_or_unpaired", {el1: {forward: d_f, reverse: d_r}}]
    then: "tool(i=C) -> {o: dataset}"
    tests:
        tool_runtime:
            tool: collection_list_paired_or_unpaired
        workflow_editor: "accepts list:paired_or_unpaired data -> list:paired_or_unpaired connection"

- doc: |
    For nested collections where each rank is a ``list`` or a ``paired`` collection,
    then collection inputs must match every part of the collection type input definition.

- example:
    label: COLLECTION_INPUT_LIST_NOT_CONSUMES_PAIRS
    assumptions:
    - datasets: [d_f, d_r]
    - tool:
        in: {i: "collection<list>"} 
        out: {o: dataset}
    - collections:
        C: [paired, {forward: d_f, reverse: d_r}]
    then: "tool(i=C)"
    is_valid: false
    tests:
        workflow_editor: "rejects connecting paired -> list"

- example:
    label: COLLECTION_INPUT_PAIRED_NOT_CONSUMES_LIST
    assumptions:
    - datasets: ["d_1,...,d_n"]
    - tool:
        in: {i: "collection<paired>"} 
        out: {o: dataset}
    - collections:
        C: [list, {i1: d_1, ..., in: d_n}]
    then: "tool(i=C)"
    is_valid: false
    tests:
        workflow_editor: "rejects connecting list -> paired"

- example:
    label: COLLECTION_INPUT_LIST_PAIRED_NOT_CONSUMES_PAIRED_PAIRED
    tests:
        workflow_editor: "rejects paired:paired -> list:paired connection"

- example:
    label: COLLECTION_INPUT_LIST_PAIRED_OR_NOT_PAIRED_NOT_CONSUMES_PAIRED_PAIRED
    tests:
        workflow_editor: "rejects paired:paired -> list:paired_or_unpaired connection"

- doc: |
    In addition to explicit collection inputs, tool inputs of ``type`` ``data``
    where ``multiple="true"`` can consume lists directly. This is likewise a
    "reduction" and does not result in implicit collection creation.

- example:
    label: LIST_REDUCTION
    assumptions:
    - datasets: ["d_1,...,d_n"]
    - tool: 
        in: {i: "dataset<multiple=true>"}
        out: {o: dataset}
    - collections:
        C: [list, {i1: d_1, ..., in: d_n}]
    then: "tool(i=C) == tool(i=[d_1,...,d_n])"
    tests:
        tool_runtime:
            api_test: "test_tools.py::TestToolsApi::test_tools.py::test_reduce_collections"
        workflow_editor: "treats multi data input as list input"

- doc: |
    Paired collections cannot be reduced this way. ``paired`` is not meant
    to represent a list/array/vector data structure - it is more like a tuple.

- example:
    label: PAIRED_REDUCTION_INVALID
    assumptions:
    - datasets: [d_f, d_r]
    - tool: 
        in: {i: "dataset<multiple=true>"}
        out: {o: dataset}
    - collections:
        C: [paired, {forward: d_f, reverse: d_r}]
    then: "tool(i=C)"
    is_valid: false
    tests:
        workflow_editor: "rejects paired input on multi-data input"

- example:
    label: PAIRED_OR_UNPAIRED_REDUCTION_INVALID
    assumptions:
    - datasets: [d_f, d_r]
    - tool: 
        in: {i: "dataset<multiple=true>"}
        out: {o: dataset}
    - collections:
        C: [paired_or_unpaired,{forward=d_f, reverse=d_r}]
    then: "tool(i=C)"
    is_valid: false
    tests:
        workflow_editor: "rejects paired_or_unpaired input on multi-data input"

- doc: "## Sub-collection Mapping"
- doc: |
    ![](https://planemo.readthedocs.io/en/master/_images/subcollection_mapping_identifiers.svg)

- example:
    label: MAPPING_LIST_PAIRED_OVER_PAIRED
    assumptions:
    - datasets: [d_f, d_r]
    - tool:
        in: {i: "collection<paired>"}
        out: {o: dataset}
    - collections:
        C: ["list:paired", {el1: {forward: d_f, reverse: d_r}}]
        "C\\_PAIRED": [paired, {forward: d_f,reverse: d_r}]
    then: "tool(i=mapOver(C, 'paired')) ~> {o: collection<list, {el1: tool(i=C\\_PAIRED)[o]}>}"
    tests:
        tool_runtime:
            api_test: "test_tools.py::TestToolsApi::test_subcollection_mapping"
        workflow_editor: "accepts list:paired -> paired connection"

- doc: |
    The natural extension of multiple data input parameters consuming list collections as describe
    above when discussing reductions is that nested lists of lists (``list:list``) can be mapped
    over a multiple data input parameter. Each nested list will be reduced by this operation but the
    results will be mapped over. The result will be a list with the same structure as the outer list
    of the input collection.

- example:
    label: NESTED_LIST_REDUCTION
    assumptions:
    - datasets: ["d_1,...,d_n"]
    - tool:
        in: {i: "dataset<multiple=true>"}
        out: {o: dataset}
    - collections:
        C: ["list:list", {o1: {inner: d_1}, ..., "on": {inner: d_n}}]
    then: "tool(i=mapOver(C, 'list')) ~> {o: collection<list,{o1: tool(i=[d_1])[o]},...,on: tool(i=[d_n])[o]}>}"
    tests:
        workflow_editor: "maps list:list over multi data input"

- doc: |
    Just as a paired collection won't be reduced by a multiple data input, any sort of nested
    collection ending in a paired collection cannot be mapped over such an input. So a multiple
    data input parameter cannot be mapped over by a list of pairs (``list:paired``) for instance.

- example:
    label: LIST_PAIRED_REDUCTION_INVALID
    assumptions:
    - datasets: [d_f, d_r]
    - tool: 
        in: {i: "dataset<multiple=true>"}
        out: {o: dataset}
    - collections:
        C: [list:paired, {forward: d_f, reverse: d_r}]
    then: "tool(i=mapOver(C, 'paired'))"
    is_valid: false
    tests:
        workflow_editor: "rejects list:paired input on multi-data input"

- example:
    label: LIST_PAIRED_OR_UNPAIRED_REDUCTION_INVALID
    assumptions:
    - datasets: [d_f, d_r]
    - tool: 
        in: {i: "dataset<multiple=true>"}
        out: {o: dataset}
    - collections:
        C: ["list:paired_or_unpaired", {forward: d_f, reverse: d_r}]
    then: "tool(i=mapOver(C, 'paired_or_unpaired'))"
    is_valid: false
    tests:
        workflow_editor: "rejects list:paired_or_unpaired input on multi-data input"

- doc: "## paired_or_unpaired Collections"
- doc: |
    The collection type ``paired_or_unpaired`` is meant to serve as a stand-in for
    an entity that can be either a single dataset or what is effectively a ``paired``
    dataset collection. These collections either have one element with identifier
    ``unpaired`` or two elements with identifiers ``forward`` and ``reverse``.

    Tools can declare a data_collection input with collection type ``paired_or_unpaired``
    and that input will consume either an explicit ``paired_or_unpaired`` collection
    normally or can consume a ``paired`` input.

- example:
    label: PAIRED_OR_UNPAIRED_CONSUMES_PAIRED
    assumptions:
    - datasets: [d_f, d_r]
    - tool:
        in: {i: "collection<paired_or_unpaired>"}
        out: {o: dataset}
    - collections:
        C: [paired, {forward: d_f, reverse: d_r}]
    - "C_AS_MIXED = CollectionInstance<paired_or_unpaired, {forward: d_f, reverse: d_r}>"
    then: "tool(i=C) == tool(i=C_AS_MIXED)"
    tests:
        tool_runtime:
            tool: collection_paired_or_unpaired
        workflow_editor: "accepts paired -> paired_or_unpaired connection"

- doc: |

    This inverse of this doesn't work intentionally. In some ways a ``paired`` collection
    acts as a ``paired_or_unpaired`` collection but a ``paired_or_unpaired`` is not a paired
    collection. This makes a lot of sense in terms of tools - a tool consuming a ``paired``
    dataset expects to find both a ``forward`` and ``reverse`` element but these may not exist
    in ``paired_or_unpaired`` collection.

- example:
    label: PAIRED_OR_UNPAIRED_NOT_CONSUMED_BY_PAIRED
    assumptions:
    - datasets: [d_f, d_r]
    - tool:
        in: {i: "collection<paired>"}
        out: {o: dataset}
    - collections:
        C: [paired_or_unpaired, {forward=d_f, reverse: d_r}]
    then: "tool(i=C) is invalid"
    tests:
        workflow_editor: "rejects paired_or_unpaired -> paired connection"

- doc: |

    The same logic holds for mapping, lists of paired datasets (``list:paired``) can be mapped over these
    ``paired_or_unpaired`` inputs and mixed lists of pairs (``list:paired_or_unpaired``) cannot
    be mapped over a ``paired`` input. Following the same logic, ``list:paired_or_unpaired`` cannot
    be mapped over a ``list`` input or multiple data input.

- example:
    label: MAPPING_LIST_PAIRED_OVER_PAIRED_OR_UNPAIRED
    assumptions:
    - datasets: [d_f, d_r]
    - tool:
        in: {i: "collection<paired_or_unpaired>"}
        out: {o: dataset}
    - collections:
        C: ["list:paired", {el: {forward: d_f, reverse: d_r}}]
        C_AS_MIXED: ["list:paired_or_unpaired", {el: {forward: d_f, reverse: d_r}}]
    then: "tool(i=mapOver(C)) == tool(i=mapOver(C_AS_MIXED))"
    tests:
        workflow_editor: "accepts list:paired -> paired_or_unpaired connection"

- example:
    label: PAIRED_OR_UNPAIRED_NOT_CONSUMED_BY_PAIRED_WHEN_MAPPING
    assumptions:
    - datasets: [d_f, d_r]
    - tool:
        in: {i: "collection<paired>"}
        out: {o: dataset}
    - collections:
        C: [list:paired_or_unpaired, {el: {forward: f, reverse: r}}]
    then: "tool(i=mapOver(C)) is invalid"
    tests:
        workflow_editor: "rejects list:paired_or_unpaired -> paired connection"

- example:
    label: PAIRED_OR_UNPAIRED_NOT_CONSUMED_BY_LIST_WHEN_MAPPING
    assumptions:
    - datasets: [d_f, d_r]
    - tool:
        in: {i: "collection<list>"}
        out: {o: dataset}
    - collections:
        C: [list:paired_or_unpaired, {el: {forward: f, reverse: r}}]
    then: "tool(i=mapOver(C)) is invalid"
    tests:
        workflow_editor: "rejects list:paired_or_unpaired -> list connection"

- doc: |
    This logic extends naturally into higher dimensional collections. A ``list:list:paired``
    can be mapped over either a ``paired_or_unpaired`` input to produce a nested list (``list:list``)
    or a ``list:paired_or_unpaired`` input to produce a flat list (``list``).

- example:
    label: MAPPING_LIST_LIST_PAIRED_OVER_PAIRED_OR_UNPAIRED
    tests:
        workflow_editor: "accepts list:list:paired -> paired_or_unpaired connection"

- doc: |

    In order for ``paired_or_unpaired`` collections to also act as a single dataset,
    a flat list can be mapped over a such an input with a special sub collection mapping
    type of 'single_datasets'.

- example:
    label: MAPPING_LIST_OVER_PAIRED_OR_UNPAIRED
    assumptions:
    - datasets: ["d_1,...,d_n"]
    - tool:
        in: {i: "collection<paired_or_unpaired>"}
        out: {o: dataset}
    - collections:
        C: [list, {i1: d_1, ..., in: d_n}]
    - "C_AS_UNPAIRED_i = CollectionInstance<paired_or_unpaired,{unpaired=di}> for i from 1...n"
    then: "tool(i=mapOver(C, 'single_datasets')) ~> {o: collection<list,{i1=tool(i=C_AS_UNPAIRED_1)[o],...,in=tool(i=C_AS_UNPAIRED_n)[o]]}>}"
    tests:
        tool_runtime:
            api_test: "test_tool_execute.py::test_map_over_paired_or_unpaired_with_list"
        workflow_editor: "accepts list -> paired_or_unpaired connection"

- doc: |
    This treatment of lists without pairing extends to nested structures naturally.
    For instance, a list of list of datasets (``list:list``) can be mapped over a
    ``paired_or_unpaired`` input to produce a nested list of lists (``list:list``)
    with a structure matching the input. Likewise, the nested list can be mapped over
    a ``list:paired_or_unpaired`` input to produce a flat list with the same structure
    as the outer list of the input.

- example:
    label: MAPPING_LIST_LIST_OVER_PAIRED_OR_UNPAIRED
    tests:
        workflow_editor: "accepts list:list -> paired_or_unpaired connection"

- example:
    label: MAPPING_LIST_LIST_OVER_LIST_PAIRED_OR_UNPAIRED
    tests:
        workflow_editor: "accepts list:list -> list:paired_or_unpaired connection"

- doc: |
    Due only implementation time, the special casing of allowing paired_or_unpaired
    act as both datasets and paired collections only works when it is the deepest
    collection type. So while list:paired can be consumed by a list:paired_or_unpaired
    input, a paired:list cannot be consumed by a paired_or_unpaired:list input though
    it should be able to for consistency. We have focused our time on data structures
    more likely to be used in actual Galaxy analyses given current and guessed future
    usage.
